import streamlit as st
import pandas as pd
import io

# ==========================================
# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
# ==========================================
st.set_page_config(
    page_title="Ù…ÙÙ‚ÙŠÙ‘Ù… Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø°ÙƒÙŠ",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Ø¥Ø¶Ø§ÙØ© Ø¨Ø¹Ø¶ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚Ø§Øª (CSS) Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…Ø¸Ù‡Ø± ÙˆØ¯Ø¹Ù… Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ù…Ù† Ø§Ù„ÙŠÙ…ÙŠÙ† Ù„Ù„ÙŠØ³Ø§Ø± (RTL) Ø¨Ø´ÙƒÙ„ Ø£ÙØ¶Ù„
st.markdown("""
    <style>
    body { direction: RTL; text-align: right; }
    .stMetric { background-color: #f0f2f6; padding: 15px; border-radius: 10px; }
    </style>
""", unsafe_allow_html=True)

# ==========================================
# Ø¹Ù†ÙˆØ§Ù† Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ÙˆØ§Ù„Ù…Ù‚Ø¯Ù…Ø©
# ==========================================
st.title("ğŸ“Š ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø¹Ù…ÙŠÙ‚ Ù„Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
st.markdown("Ù‡Ø°Ø§ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ÙŠØ³Ø§Ø¹Ø¯Ùƒ Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„ Ø¬ÙˆØ¯Ø© Ø¨ÙŠØ§Ù†Ø§ØªÙƒ Ù„ÙŠØ³ ÙÙ‚Ø· Ø¢Ù„ÙŠØ§Ù‹ØŒ Ø¨Ù„ **Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ÙÙ‡Ù…Ùƒ Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¹Ù…Ù„ (Business Rules)** Ø§Ù„Ø®Ø§ØµØ© Ø¨Ø¨ÙŠØ§Ù†Ø§ØªÙƒ.")

# ==========================================
# Ø¯Ø§Ù„Ø© Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª
# ==========================================
@st.cache_data
def load_data(uploaded_file):
    try:
        if uploaded_file.name.endswith('.csv'):
            df = pd.read_csv(uploaded_file)
        elif uploaded_file.name.endswith(('.xls', '.xlsx')):
            df = pd.read_excel(uploaded_file)
        else:
            return None
        return df
    except Exception as e:
        st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù: {e}")
        return None

# ==========================================
# Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰: Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù
# ==========================================
st.header("1. Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ğŸ“")
uploaded_file = st.file_uploader("Ù‚Ù… Ø¨Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (CSV Ø£Ùˆ Excel)", type=['csv', 'xlsx', 'xls'])

if uploaded_file is not None:
    # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    df = load_data(uploaded_file)
    
    if df is not None:
        st.success(f"ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ø¨Ù†Ø¬Ø§Ø­! ÙŠØ­ØªÙˆÙŠ Ø§Ù„Ù…Ù„Ù Ø¹Ù„Ù‰ {df.shape[0]} ØµÙ Ùˆ {df.shape[1]} Ø¹Ù…ÙˆØ¯.")
        
        with st.expander("ğŸ‘€ Ù†Ø¸Ø±Ø© Ø³Ø±ÙŠØ¹Ø© Ø¹Ù„Ù‰ Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"):
            st.dataframe(df.head())

        # ==========================================
        # Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ©: Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠØ© (Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¹Ù…Ù„)
        # ==========================================
        st.header("2. ØªØ­Ø¯ÙŠØ¯ Ù…Ø¹Ø§ÙŠÙŠØ± Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ğŸ“")
        st.markdown("ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ© Ù„ØªØ­Ø¯ÙŠØ¯ Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø¬ÙˆØ¯Ø© Ø§Ù„Ø®Ø§ØµØ© Ø¨Ù‡Ø°Ù‡ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:")
        
        columns = df.columns.tolist()
        numeric_columns = df.select_dtypes(include=['int64', 'float64']).columns.tolist()
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ (Form) Ù„Ø¬Ù…Ø¹ Ø¥Ø¬Ø§Ø¨Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
        with st.form("dq_rules_form"):
            st.subheader("Ù…Ø¹ÙŠØ§Ø± Ø§Ù„ØªÙØ±Ø¯ (Uniqueness)")
            # Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø£ÙˆÙ„: Ø§Ù„Ù…Ø¹Ø±Ù Ø§Ù„ÙØ±ÙŠØ¯
            primary_key = st.selectbox(
                "Ù…Ø§ Ù‡Ùˆ Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø°ÙŠ ÙŠÙ…Ø«Ù„ Ø§Ù„Ù…Ø¹Ø±Ù‘Ù Ø§Ù„ÙØ±ÙŠØ¯ Ù„ÙƒÙ„ ØµÙ (Ù…Ø«Ù„: Ø±Ù‚Ù… Ø§Ù„Ù‡ÙˆÙŠØ©ØŒ ÙƒÙˆØ¯ Ø§Ù„Ù…Ù†ØªØ¬) ÙˆÙ„Ø§ ÙŠØ¬Ø¨ Ø£Ù† ÙŠØªÙƒØ±Ø± Ø£Ø¨Ø¯Ø§Ù‹ØŸ",
                options=["Ù„Ø§ ÙŠÙˆØ¬Ø¯"] + columns
            )
            
            st.subheader("Ù…Ø¹ÙŠØ§Ø± Ø§Ù„Ø§ÙƒØªÙ…Ø§Ù„ (Completeness)")
            # Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø«Ø§Ù†ÙŠ: Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø¥Ù„Ø²Ø§Ù…ÙŠØ©
            mandatory_columns = st.multiselect(
                "Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø¥Ù„Ø²Ø§Ù…ÙŠØ© Ø§Ù„ØªÙŠ ÙŠÙÙ…Ù†Ø¹ Ù…Ù†Ø¹Ø§Ù‹ Ø¨Ø§ØªØ§Ù‹ Ø£Ù† ØªÙƒÙˆÙ† ÙØ§Ø±ØºØ© (Null/Empty)ØŸ",
                options=columns
            )
            
            st.subheader("Ù…Ø¹ÙŠØ§Ø± Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ© (Validity)")
            # Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø«Ø§Ù„Ø«: Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø³Ø§Ù„Ø¨Ø© (Ù„Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ© ÙÙ‚Ø·)
            if numeric_columns:
                positive_only_columns = st.multiselect(
                    "Ù‡Ù„ Ù‡Ù†Ø§Ùƒ Ø£Ø¹Ù…Ø¯Ø© Ø±Ù‚Ù…ÙŠØ© ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ù‚ÙŠÙ…Ù‡Ø§ Ù…ÙˆØ¬Ø¨Ø© Ø¯Ø§Ø¦Ù…Ø§Ù‹ (Ù…Ø«Ù„: Ø§Ù„Ø³Ø¹Ø±ØŒ Ø§Ù„Ø¹Ù…Ø±ØŒ Ø§Ù„ÙƒÙ…ÙŠØ©)ØŸ",
                    options=numeric_columns
                )
            else:
                positive_only_columns = []
                st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø¹Ù…Ø¯Ø© Ø±Ù‚Ù…ÙŠØ© ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù Ù„ØªØ·Ø¨ÙŠÙ‚ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø¹ÙŠØ§Ø±.")
                
            # Ø²Ø± Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„
            analyze_button = st.form_submit_button("ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù…ÙŠÙ‚ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¥Ø¬Ø§Ø¨Ø§ØªÙŠ")

        # ==========================================
        # Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø«Ø§Ù„Ø«Ø©: Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù…ÙŠÙ‚ ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        # ==========================================
        if analyze_button:
            st.markdown("---")
            st.header("3. ØªÙ‚Ø±ÙŠØ± Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙØµÙŠÙ„ÙŠ ğŸ“ˆ")
            
            # ØªÙ‡ÙŠØ¦Ø© Ù…ØªØºÙŠØ±Ø§Øª Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†Ù‚Ø§Ø· (Scoring)
            total_rows = len(df)
            issues_found = False
            
            # 1. ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙØ±Ø¯ (Uniqueness)
            if primary_key != "Ù„Ø§ ÙŠÙˆØ¬Ø¯":
                st.subheader(f"ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙØ±Ø¯ Ù„Ø¹Ù…ÙˆØ¯: `{primary_key}`")
                duplicated_rows = df[df.duplicated(subset=[primary_key], keep=False)]
                duplicate_count = len(duplicated_rows)
                
                if duplicate_count > 0:
                    uniqueness_score = ((total_rows - duplicate_count) / total_rows) * 100
                    st.warning(f"ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {duplicate_count} ØµÙ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù‚ÙŠÙ… Ù…ÙƒØ±Ø±Ø© ÙÙŠ Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù…Ø¹Ø±Ù Ø§Ù„ÙØ±ÙŠØ¯!")
                    st.metric("Ù†Ø³Ø¨Ø© Ø§Ù„ØªÙØ±Ø¯ (Uniqueness Score)", f"{uniqueness_score:.1f}%")
                    with st.expander("Ø¹Ø±Ø¶ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù…ÙƒØ±Ø±Ø©"):
                        st.dataframe(duplicated_rows.sort_values(by=primary_key))
                    issues_found = True
                else:
                    st.success("Ù…Ù…ØªØ§Ø²! Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø£ÙŠ ØªÙƒØ±Ø§Ø± ÙÙŠ Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù…Ø¹Ø±Ù Ø§Ù„ÙØ±ÙŠØ¯. (Ù†Ø³Ø¨Ø© Ø§Ù„ØªÙØ±Ø¯: 100%)")
            
            # 2. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ÙƒØªÙ…Ø§Ù„ (Completeness)
            if mandatory_columns:
                st.subheader("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ÙƒØªÙ…Ø§Ù„ Ù„Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø¥Ù„Ø²Ø§Ù…ÙŠØ©")
                
                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„ØµÙÙˆÙ Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù‚ÙŠÙ… ÙØ§Ø±ØºØ© ÙÙŠ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©
                missing_data_mask = df[mandatory_columns].isnull().any(axis=1)
                missing_rows = df[missing_data_mask]
                missing_count = len(missing_rows)
                
                if missing_count > 0:
                    completeness_score = ((total_rows - missing_count) / total_rows) * 100
                    st.warning(f"ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {missing_count} ØµÙ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ù…ÙÙ‚ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø¥Ù„Ø²Ø§Ù…ÙŠØ©!")
                    st.metric("Ù†Ø³Ø¨Ø© Ø§Ù„Ø§ÙƒØªÙ…Ø§Ù„ (Completeness Score)", f"{completeness_score:.1f}%")
                    
                    # ØªÙØµÙŠÙ„ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©
                    missing_stats = df[mandatory_columns].isnull().sum()
                    missing_stats = missing_stats[missing_stats > 0]
                    st.write("ØªÙØµÙŠÙ„ Ø§Ù„Ù†ÙˆØ§Ù‚Øµ Ø­Ø³Ø¨ Ø§Ù„Ø¹Ù…ÙˆØ¯:")
                    st.bar_chart(missing_stats)
                    
                    with st.expander("Ø¹Ø±Ø¶ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„ØªÙŠ Ø¨Ù‡Ø§ Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ø²Ø§Ù…ÙŠØ© Ù…ÙÙ‚ÙˆØ¯Ø©"):
                        st.dataframe(missing_rows)
                    issues_found = True
                else:
                    st.success("Ø±Ø§Ø¦Ø¹! Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø¥Ù„Ø²Ø§Ù…ÙŠØ© Ù…ÙƒØªÙ…Ù„Ø© Ø¨Ù†Ø³Ø¨Ø© 100%.")

            # 3. ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ© Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠØ© (Validity - Positive Values)
            if positive_only_columns:
                st.subheader("ğŸ” ØªØ­Ù„ÙŠÙ„ ØµÙ„Ø§Ø­ÙŠØ© Ø§Ù„Ø£Ø±Ù‚Ø§Ù… (Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙˆØ¬Ø¨Ø© ÙÙ‚Ø·)")
                
                invalid_rows_list = []
                for col in positive_only_columns:
                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØµÙÙˆÙ Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù‚ÙŠÙ… Ø£ØµØºØ± Ù…Ù† Ø§Ù„ØµÙØ±
                    invalid = df[df[col] < 0]
                    if not invalid.empty:
                        invalid_rows_list.append((col, invalid))
                
                if invalid_rows_list:
                    st.error("ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù‚ÙŠÙ… Ø³Ø§Ù„Ø¨Ø© ØºÙŠØ± Ù…Ù†Ø·Ù‚ÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ØªØ­Ø¯ÙŠØ¯Ùƒ!")
                    for col, invalid_df in invalid_rows_list:
                        st.write(f"- Ø¹Ù…ÙˆØ¯ `{col}` ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ **{len(invalid_df)}** Ù‚ÙŠÙ…Ø© Ø³Ø§Ù„Ø¨Ø©.")
                        with st.expander(f"Ø¹Ø±Ø¶ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø³Ø§Ù„Ø¨Ø© ÙÙŠ {col}"):
                            st.dataframe(invalid_df)
                    issues_found = True
                else:
                    st.success("ØªÙ… Ø§Ù„ØªØ­Ù‚Ù‚! Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù‚ÙŠÙ… ÙÙŠ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© Ù…ÙˆØ¬Ø¨Ø© ÙˆÙ…Ù†Ø·Ù‚ÙŠØ© Ø¨Ù†Ø³Ø¨Ø© 100%.")

            # Ø§Ù„Ø®Ù„Ø§ØµØ© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
            st.markdown("---")
            if not issues_found:
                st.balloons()
                st.success("ğŸ‰ ØªÙ‡Ø§Ù†ÙŠÙ†Ø§! Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„ØªÙŠ Ø­Ø¯Ø¯ØªÙ‡Ø§ØŒ Ø¨ÙŠØ§Ù†Ø§ØªÙƒ ÙÙŠ Ø­Ø§Ù„Ø© Ù…Ù…ØªØ§Ø²Ø© ÙˆØªØ®Ù„Ùˆ Ù…Ù† Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø­Ø±Ø¬Ø©.")
            else:
                st.info("ğŸ’¡ **Ù†ØµÙŠØ­Ø©:** ÙŠØ±Ø¬Ù‰ Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù…Ø¹Ø±ÙˆØ¶Ø© Ø£Ø¹Ù„Ø§Ù‡ ÙˆØªØµØ­ÙŠØ­Ù‡Ø§ ÙÙŠ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ØµÙ„ÙŠ Ù„Ø¶Ù…Ø§Ù† Ø¬ÙˆØ¯Ø© Ø¨ÙŠØ§Ù†Ø§ØªÙƒ Ù‚Ø¨Ù„ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø£Ùˆ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬.")
